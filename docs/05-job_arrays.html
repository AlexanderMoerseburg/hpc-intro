<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>HPC Course: Parallelising</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/accessible-code-block-0.0.1/empty-anchor.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="assets/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img id="logo" style="height: 25px;" src="assets/img/logo.svg" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="99-setup.html">Setup</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Materials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01-intro.html">Introduction to HPC</a>
    </li>
    <li>
      <a href="02-working_on_hpc.html">Working on a HPC cluster</a>
    </li>
    <li>
      <a href="03-slurm.html">Using the SLURM Job Scheduler</a>
    </li>
    <li>
      <a href="04-software.html">Managing Software</a>
    </li>
    <li>
      <a href="05-job_arrays.html">Parallelising Jobs</a>
    </li>
    <li>
      <a href="99-cambridge_hpc.html">Cambridge HPC Resources</a>
    </li>
  </ul>
</li>
<li>
  <a href="99-exercises.html">Exercises</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="99-unix_cheatsheet.html">Unix Cheatsheet</a>
    </li>
    <li>
      <a href="99-slurm_cheatsheet.html">SLURM Quick Reference</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/cambiotraining">GitHub</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">




</div>


<div id="parallelising-jobs" class="section level1">
<h1>Parallelising Jobs</h1>
<div class="highlight">
<h4 id="questions">Questions</h4>
<ul>
<li>How can I parallelise jobs on a HPC?</li>
<li>How can I automate job parallelisation?</li>
</ul>
<h4 id="learning-objectives">Learning Objectives</h4>
<ul>
<li>Distinguish between different kinds of parallel computations: multi-threading within a job and job parallelisation across independent jobs.</li>
<li>Use SLURM <em>job arrays</em> to automatically submit several parallel jobs.</li>
<li>Customise each parallel job of an array to use different input -&gt; output.</li>
</ul>
</div>
<div id="parallelising-tasks" class="section level2">
<h2>Parallelising Tasks</h2>
<p>One of the important concepts in the use of a HPC is <strong>parallelisation</strong>. This concept is used in different ways, and can mean slightly different things.</p>
<p>A program may internally support parallel computation for some of its tasks, which we may refer to as <em>multi-threading</em> or <em>multi-core processing</em>. In this case, there is typically a single set of “input -&gt; output”, so all the parallel computations need to finish in order for us to obtain our result. In other words, there is some dependency between those parallel calculations.</p>
<p>On the other hand, we may want to run the same program on different inputs, where each run is completely independent from the previous run. In these cases we say the task is “embarrassingly parallel”. Usually, running tasks completely in parallel is faster, since we remove the need to keep track of what each task’s status is (since they are independent of each other).</p>
<p>Finally, we may want to do both things: run several jobs in parallel, while each of the jobs does some internal parallelisation of its computations (multi-threading).</p>
<div class="figure">
<img src="images/parallel.svg" alt="" />
<p class="caption">Schematic of parallelisation.</p>
</div>
<div class="note">
<p><strong>Terminology Alert!</strong></p>
<p>Some software packages have an option to specify how many CPU cores to use in their computations (i.e. they can parallelise their calculations). However, in their documentation this you may be referred to as <strong>cores</strong>, <strong>processors</strong>, <strong>CPUs</strong> or <strong>threads</strong>, which are used more or less interchangeably to essentially mean “how many calculations should I run in parallel?”. Although these terms are technically different, when you see this mentioned in the software’s documentation, usually you want to set it as the number of CPU cores you request from the cluster.</p>
</div>
</div>
<div id="job-arrays" class="section level2">
<h2>Job Arrays</h2>
<p>There are several ways to parallelise jobs on a HPC. One of them is to use a built-in functionality in SLURM called <strong>job arrays</strong>.</p>
<p><em>Job arrays</em> are a collection of jobs that run in parallel with identical parameters. Any resources you request (e.g. <code>-c</code>, <code>--mem</code>, <code>-t</code>) apply to each individual job of the “array”. This means that you only need to submit one “master” job, making it easier to manage and automate your analysis using a single script.</p>
<p>Job arrays are created with the <em>SBATCH</em> option <code>-a START-FINISH</code> where <em>START</em> and <em>FINISH</em> are integers defining the range of array numbers created by SLURM. SLURM then creates a special shell variable <code>$SLURM_ARRAY_TASK_ID</code>, which contains the array number for the job being processed. Later in this section we will see how we can use some tricks with this variable to automate our analysis.</p>
<p>For now let’s go through this simple example, which shows what a job array looks like (you can find this script in the course folder <code>slurm/parallel_arrays.sh</code>):</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># ... some lines omitted ...</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co">#SBATCH -o logs/parallel_arrays_%a.log</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">#SBATCH -a 1-3</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="bu">echo</span> <span class="st">&quot;This is task number </span><span class="va">$SLURM_ARRAY_TASK_ID</span><span class="st">&quot;</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="bu">echo</span> <span class="st">&quot;Using </span><span class="va">$SLURM_CPUS_PER_TASK</span><span class="st"> CPUs&quot;</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="bu">echo</span> <span class="st">&quot;Running on:&quot;</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="fu">hostname</span></span></code></pre></div>
<p>Submitting this script with <code>sbatch slurm/parallel_arrays.sh</code> will launch 3 jobs. The “<em>%a</em>” keyword is used in our output filename (<code>-o</code>) and will be replaced by the array number, so that we end up with three files: <code>parallel_arrays_1.log</code>, <code>parallel_arrays_2.log</code> and <code>parallel_arrays_3.log</code>. Looking at the output in those files should make it clearer that <code>$SLURM_ARRAY_TASK_ID</code> stores the array number of each job, and that each of them uses 2 CPUS (<code>-c 2</code> option). The compute node that they run on may be variable (depending on which node was available to run each job).</p>
<div class="note">
<p>You can define job array numbers in multiple ways, not just sequencially.</p>
<details>
<p><summary>More</summary> Here are some examples taken from SLURM’s Job Array Documentation:</p>
<table>
<colgroup>
<col width="22%" />
<col width="77%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Option</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>-a 0-31</code></td>
<td align="left">index values between 0 and 31</td>
</tr>
<tr class="even">
<td align="right"><code>-a 1,3,5,7</code></td>
<td align="left">index values of 1, 3, 5 and 7</td>
</tr>
<tr class="odd">
<td align="right"><code>-a 1-7:2</code></td>
<td align="left">index values between 1 and 7 with a step size of 2 (i.e. 1, 3, 5 and 7)</td>
</tr>
</tbody>
</table>
</details>
</div>
<div class="exercise">
<p>Previously, we used the <code>pi_estimator.R</code> script to obtain an estimate of the number Pi. Since this is done using a stochastic algorithm, we may want to run it several times to get a sense of the error associated with our estimate.</p>
<ol style="list-style-type: decimal">
<li>Use <em>VS Code</em> to open the SLURM submission script in <code>slurm/parallel_estimate_pi.sh</code>. Adjust the <code>#SBATCH</code> options, to run the job 10 times using a job array.</li>
<li>Launch the job with <code>sbatch</code>, monitor its progress and examine the output.
<details>
<summary>Hint</summary> Note that the output of <code>pi_estimator.R</code> is now being <em>appended</em> to a text file with <code>pi_estimator.R &gt;&gt; results/pi_estimates.txt</code>. So the output of all the 100 jobs of the array will be written to this same file, one after the other.
</details></li>
</ol>
<details>
<p><summary>Answer</summary></p>
<p><strong>A1.</strong></p>
<p>In our script, we need to add <code>#SBATCH -a 1-10</code> as one of our options, so that when we submit this scrit to <code>sbatch</code>, it will run 100 iterations of it in parallel.</p>
<p><strong>A2.</strong></p>
<p>We can launch our adjusted script with <code>sbatch slurm/parallel_estimate_pi.sh</code>. When we check our jobs with <code>squeue -u USERNAME</code>, we will notice several jobs with JOBID in the format “ID_1”, “ID_2”, etc. These indicate the number of the array that is currently running as part of that job submission.</p>
<p>In this case, we only specified a single output log file in <code>#SBATCH -o</code> (we did not use the <code>%a</code> keyword). So all the information about the jobs was sent to a single file in <code>logs/parallel_estimate_pi.log</code>.</p>
<p>However, for our actual estimate of Pi, we redirected (<code>&gt;&gt;</code>) the output to a text file in <code>results/pi_estimate.txt</code>. If we examine this file (e.g. with <code>less results/pi_estimate.txt</code>) we can see it has the results of all the runs of our simulation.</p>
</details>
</div>
<div id="using-slurm_array_task_id-to-automate-jobs" class="section level3">
<h3>Using <code>$SLURM_ARRAY_TASK_ID</code> to Automate Jobs</h3>
<p>One way to automate our jobs is to use the job array number (stored in the <code>$SLURM_ARRAY_TASK_ID</code> variable) with some command-line tricks. The trick we will demonstrate here is to parse a CSV file to read input parameters for our scripts.</p>
<p>For example, in our <code>data/</code> folder we have the following file, which includes information about parameter values we want to use with a tool in our next exercise.</p>
<pre class="console"><code>$ cat data/turing_model_parameters.csv</code></pre>
<pre><code>f,k
0.055,0.062
0.03,0.055
0.046,0.065
0.059,0.061</code></pre>
<p>This is a CSV (comma-separated values) format, with two “columns” named “f” and “k”. Let’s say we wanted to obtain information for the 2rd set of parameters, which in this case is in the 3rd line of the file (because of the column header). We can get the top N lines of a file using the <code>head</code> command (we pipe the output of the previous <code>cat</code> command):</p>
<pre class="console"><code>$ cat data/turing_model_parameters.csv | head -n 3</code></pre>
<p>This gets us lines 1-3 of the file. To get just the information about that 2nd set of parameters, we can now <em>pipe</em> the output of the <code>head</code> command to the command that gets us the bottom lines of a file <code>tail</code>:</p>
<pre class="console"><code>$ cat data/turing_model_parameters.csv | head -n 3 | tail -n 1</code></pre>
<p>Finally, to separate the two values that are separated by a comma, we can use the <code>cut</code> command, which accepts a <em>delimiter</em> (<code>-d</code> option) and a <em>field</em> we want it to return (<code>-f</code> option):</p>
<pre class="console"><code>$ cat data/turing_model_parameters.csv | head -n 3 | tail -n 1 | cut -d &quot;,&quot; -f 1</code></pre>
<p>In this example, we use comma as a delimiter field and obtained the first of the values after “cutting” that line.</p>
<p>Schematically, this is what we’ve done:</p>
<p><img src="images/head_tail.png" /></p>
<p>So, if we wanted to use job arrays to automatically retrieve the relevant line of this file as its input, we could use <code>head -n $SLURM_ARRAY_TASK_ID</code> in our command pipe above. Let’s see this in practice in our next exercise.</p>
<div class="exercise">
A PhD student is working on project to understand how different patterns, such as animal stripes and coral colonies, form in nature. They are using a type of model, first proposed by <a href="https://en.wikipedia.org/wiki/Turing_pattern">Alan Turing</a>, which models the interaction between two components that can difuse in space and promote/inhibit each other.
<details>
<p><summary>More</summary></p>
<p>Turing patterns can be generated with a type of mathematical model called a “Reaction-diffusion system”. It models two substances - A and B - that can difuse in space and interact with each other in the following way: substance A self-activates itself and also activates B; B inhibits A.</p>
<div class="figure">
<img src="https://ars.els-cdn.com/content/image/3-s2.0-B9780123821904000061-f06-05-9780123821904.jpg" alt="" />
<p class="caption"><a href="https://doi.org/10.1016/B978-0-12-382190-4.00006-1" class="uri">https://doi.org/10.1016/B978-0-12-382190-4.00006-1</a></p>
</div>
<p>This seemingly simple interaction can generate complex spatial patterns, some of which capture the diversity of patterns observed in nature. Here is a very friendly video illustrating this: <a href="https://youtu.be/alH3yc6tX98" class="uri">https://youtu.be/alH3yc6tX98</a></p>
</details>
<p>They have a python script which runs this model and produces an output image as exemplified above. The two main parameters in the model are called “feed” and “kill”, and their python script accepts these as options, for example:</p>
<pre class="console"><code>$ python scripts/turing_model.py --feed 0.04 --kill 0.06 --outdir results/turing/</code></pre>
<p>This would produce an image saved as <code>results/turing/f0.04_k0.06.png</code>.</p>
<p>The student has been running this script on their laptop, but it takes a while to run and they would like to try several parameter combinations. They have prepared a CSV file in <code>data/turing_model_parameters.csv</code> with parameter values of interest (you can open this file in <em>VS Code</em> to quickly inspect its contents).</p>
<p>Our objective is to automate running these models in parallel on the HPC.</p>
<ol style="list-style-type: decimal">
<li>Use <em>VS Code</em> to open the SLURM submission script in <code>slurm/parallel_turing_pattern.sh</code>. The first few lines of the code are used to fetch parameter values from the CSV file, using the special <code>$SLURM_ARRAY_TASK_ID</code> variable. Fix the <code>#SBATCH -a</code> option to get these values from the CSV file.
<details>
<summary>Hint</summary>The array should have as many numbers as there are lines in our CSV file. However, make sure the array number starts at 2 because the CSV file has a header with column names.
</details></li>
<li>Launch the job with <code>sbatch</code> and monitor its progress (<code>squeue</code>), whether it runs successfully (<code>scontrol show job</code>), and examine the SLURM output log files.</li>
<li>Examine the output files in the <code>results/turing/</code> folder (Note: you can preview image files by opening them in <em>VS Code</em>.)</li>
</ol>
<details>
<p><summary>Answer</summary></p>
<p><strong>A1.</strong></p>
<p>Our array numbers should be: <code>#SBATCH -a 2-5</code>. We start at 2, because the parameter values start at the second line of the parameter file. We finish at 5, because that’s the number of lines in the CSV file.</p>
<p><strong>A2.</strong></p>
<p>We can submit the script with <code>sbatch slurm/parallel_turing_pattern.sh</code>. While the job is running we can monitor its status with <code>squeue -u USERNAME</code>. We should see several jobs listed with IDs as <code>JOBID_ARRAYID</code> format.</p>
<p>Because we used the <code>%a</code> keyword in our <code>#SBATCH -o</code> option, we will have an output log file for each job of the array. We can list these log files with <code>ls logs/parallel_turing_pattern_*.log</code> (using the "*" wildcard to match any character). If we examine the content of one of these files (e.g. <code>cat logs/parallel_turing_pattern_1.log</code>), we should only see the messages we printed with the <code>echo</code> commands. The actual output of the python script is an image, which is saved into the <code>results/turing</code> folder.</p>
<p><strong>A3.</strong></p>
<p>Once all the array jobs finish, we should have 5 image files in <code>ls results/turing</code>. We can open these images from within <em>VS Code</em>, or alternatively we could move them to our computer with <em>Filezilla</em> (or the command-line <code>scp</code> or <code>rsync</code> commands), as we covered in the <a href="02-working_on_hpc.html#Moving_Files">Moving Files Session</a>.</p>
</details>
</div>
<div class="exercise">
<p>(This is a bioinformatics-flavoured version of the previous exercise.)</p>
<p>Continuing from our previous exercise where we <a href="04-software.html#Loading_Conda_Environments">prepared our <em>Drosophila</em> genome for bowtie2</a>, we now want to map each of our samples’ sequence data to the reference genome.</p>
<p><img src="images/mapping.png" style="width:50.0%" /></p>
<p>Looking at our data directory (<code>ls hpc_workshop/data/reads</code>), we can see several sequence files in standard <em>fastq</em> format. These files come in pairs (with suffix "_1" and "_2"), and we have 8 different samples. Ideally we want to process these samples in parallel in an automated way.</p>
<p>We have created a CSV file with three columns. One column contains the sample’s name (which we will use for our output files) and the other two columns contain the path to the first and second pairs of the input files. With the information on this table, we should be able to automate our data processing using a SLURM job array.</p>
<ol style="list-style-type: decimal">
<li>Use <em>VS Code</em> to open the SLURM submission script in <code>slurm/parallel_drosophila_mapping.sh</code>. The first few lines of the code are used to fetch parameter values from the CSV file, using the special <code>$SLURM_ARRAY_TASK_ID</code> variable. Fix the <code>#SBATCH -a</code> option to get these values from the CSV file.
<details>
<summary>Hint</summary>The array should have as many numbers as there are lines in our CSV file. However, make sure the array number starts at 2 because the CSV file has a header with column names.
</details></li>
<li>Launch the job with <code>sbatch</code> and monitor its progress (<code>squeue</code>), whether it runs successfully (<code>scontrol show job</code>), and examine the SLURM output log files.</li>
<li>Examine the output files in the <code>results/drosophila/mapping</code> folder. (Note: the output files are text-based, so you can examine them by using the command line program <code>less</code>, for example.)</li>
</ol>
<details>
<p><summary>Answer</summary></p>
<p><strong>A1.</strong></p>
<p>Our array numbers should be: <code>#SBATCH -a 2-9</code>. We start at 2, because the parameter values start at the second line of the parameter file. We finish at 9, because that’s the number of lines in the CSV file.</p>
<p><strong>A2.</strong></p>
<p>We can submit the script with <code>sbatch slurm/parallel_drosophila_mapping.sh</code>. While the job is running we can monitor its status with <code>squeue -u USERNAME</code>. We should see several jobs listed with IDs as <code>JOBID_ARRAYID</code> format.</p>
<p>Because we used the <code>%a</code> keyword in our <code>#SBATCH -o</code> option, we will have an output log file for each job of the array. We can list these log files with <code>ls logs/parallel_drosophila_mapping_*.log</code> (using the "*" wildcard to match any character). If we examine the content of one of these files (e.g. <code>cat logs/parallel_drosophila_mapping_1.log</code>), we should only see the messages we printed with the <code>echo</code> commands. The actual output of the <code>bowtie2</code> program is a file in [SAM](<a href="https://en.wikipedia.org/wiki/SAM_(file_format)" class="uri">https://en.wikipedia.org/wiki/SAM_(file_format)</a> format, which is saved into the <code>results/drosophila/mapping</code> folder.</p>
<p><strong>A3.</strong></p>
<p>Once all the array jobs finish, we should have 8 SAM files in <code>ls results/drosophila/mapping</code>. We can examine the content of these files, although they are not terribly useful by themselves. In a typical bioinformatics workflow these files would be used for further analysis, for example SNP-calling.</p>
</details>
</div>
</div>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<div class="highlight">
<h4 id="key-points">Key Points</h4>
<ul>
<li>Some tools internally parallelise some of their computations, which is usually referred to as <em>multi-threading</em> or <em>multi-core processing</em>.</li>
<li>When computational tasks are independent of each other, we can use job parallelisation to make them more efficient.</li>
<li>We can automatically generate parallel jobs using SLURM job arrays with the <code>sbatch</code> option <code>-a</code>.</li>
<li>SLURM creates a variable called <code>$SLURM_ARRAY_TASK_ID</code>, which can be used to customise each individual job of the array.
<ul>
<li>For example we can obtain the input/output information from a simple configuration text file using some command line tools: <code>cat config.csv | head -n $SLURM_ARRAY_TASK_ID | tail -n 1</code></li>
</ul></li>
</ul>
<h4 id="further-resources">Further resources</h4>
<ul>
<li><a href="https://slurm.schedmd.com/job_array.html">SLURM Job Array Documentation</a></li>
</ul>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
