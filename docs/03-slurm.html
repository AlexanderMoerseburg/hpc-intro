<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>HPC Course: SLURM</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/accessible-code-block-0.0.1/empty-anchor.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="assets/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img id="logo" style="height: 25px;" src="assets/img/logo.svg" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="99-setup.html">Setup</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Materials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01-intro.html">Introduction to HPC</a>
    </li>
    <li>
      <a href="02-working_on_hpc.html">Working on a HPC cluster</a>
    </li>
    <li>
      <a href="03-slurm.html">Using the SLURM Job Scheduler</a>
    </li>
    <li>
      <a href="04-software.html">Managing Software</a>
    </li>
    <li>
      <a href="05-job_arrays.html">Parallelising Jobs</a>
    </li>
    <li>
      <a href="99-cambridge_hpc.html">Cambridge HPC Resources</a>
    </li>
  </ul>
</li>
<li>
  <a href="99-exercises.html">Exercises</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extras
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="99-unix_cheatsheet.html">Unix Cheatsheet</a>
    </li>
    <li>
      <a href="99-slurm_cheatsheet.html">SLURM Quick Reference</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/cambiotraining">GitHub</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">




</div>


<div id="using-the-slurm-job-scheduler" class="section level1">
<h1>Using the SLURM Job Scheduler</h1>
<div class="highlight">
<h4 id="questions">Questions</h4>
<ul>
<li>How do I submit jobs to the HPC?</li>
<li>How can I customise my jobs?</li>
<li>How can I estimate how many resources I need for a job?</li>
</ul>
<h4 id="lesson-objectives">Lesson Objectives</h4>
<ul>
<li>Submit a simple job using SLURM and analyse its output.</li>
<li>Edit a job submission script to request non-default resources.</li>
<li>Use SLURM environment variables to customise scripts.</li>
<li>Use the commands <code>squeue</code> and <code>sacct</code> to obtain information about the jobs.</li>
<li>Troubleshoot errors occurring during job execution.</li>
</ul>
</div>
<div id="job-scheduler-overview" class="section level2">
<h2>Job Scheduler Overview</h2>
<p>As we briefly discussed in “<a href="01-intro.html">Introduction to HPC</a>”, HPC servers usually have a <em>job scheduling</em> software that manages all the jobs that the users submit to be run on the <em>compute nodes</em>. This allows efficient usage of the compute resources (CPUs and RAM), and the user does not have to worry about affecting other people’s jobs.</p>
<p>The job scheduler uses an algorithm to prioritise the jobs, weighing aspects such as:</p>
<ul>
<li>how much time did you request to run your job?</li>
<li>how many resources (CPUs and RAM) do you need?</li>
<li>how many other jobs have you got running at the moment?</li>
</ul>
<p>Based on these, the algorithm will rank each of the jobs in the queue to decide on a “fair” way to prioritise them. Note that this priority dynamically changes all the time, as jobs are submitted or cancelled by the users, and depending on how long they have been in the queue. For example, a job requesting many resources may start with a low priority, but the longer it waits in the queue, the more its priority increases.</p>
</div>
<div id="submitting-a-job-with-slurm" class="section level2">
<h2>Submitting a Job with SLURM</h2>
<p>To submit a job to SLURM, you need to include your code in a <em>shell script</em>. Let’s start with a minimal example, found in our workshop data folder “slurm”.</p>
<p>Our script is called <code>simple_job.sh</code> and contains the following code:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">sleep</span> 60 <span class="co"># hold for 60 seconds</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="bu">echo</span> <span class="st">&quot;This job is running on:&quot;</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">hostname</span></span></code></pre></div>
<p>We can run this script from the login node using the <code>bash</code> interpreter (make sure you are in the correct directory first: <code>cd ~/scratch/hpc_workshop/</code>):</p>
<pre class="console"><code>bash slurm/simple_job.sh</code></pre>
<p>Which prints the output:</p>
<pre><code>This job is running on:
login-node</code></pre>
<p>To submit the job to the scheduler we instead use the <code>sbatch</code> command in a very similar way:</p>
<pre class="console"><code>sbatch slurm/simple_job.sh</code></pre>
<p>In this case, we are informed that the job is submitted, but the output is not printed back on the console. Instead the output is sent to a file, by default named as <code>slurm-JOBID.out</code>, where “JOBID” is a number corresponding to the job ID assigned to the job by the scheduler. This file will be located in the same directory where you launched the job from.</p>
<p>We can investigate the output by looking inside the file, for example <code>cat slurm-JOBID.out</code>.</p>
<div class="note">
<p>The first line of the shell scripts <code>#!/bin/bash</code> is called a <a href="https://en.wikipedia.org/wiki/Shebang_(Unix)"><em>shebang</em></a> and indicates which program should interpret this script. In this case, <em>bash</em> is the interpreter of <em>shell</em> scripts (there’s other shell interpreters, but that’s beyond what we need to worry about here).</p>
<p>Remember to <strong>always have this as the first line of your script</strong>. If you don’t, <code>sbatch</code> will throw an error.</p>
</div>
</div>
<div id="configuring-job-options" class="section level2">
<h2>Configuring Job Options</h2>
<p>Although the above example works, our job just ran with the default options that SLURM was configured with. Instead, we usually want to customise our job, by specifying options at the top of the script using the <code>#SBATCH</code> keyword, followed by the SLURM option.</p>
<p>For example, one option we may want to change in our previous script is the name of the file to where our standard output is written to. We can do this using the <code>-o</code> option.</p>
<p>Here is how we could modify our script (you can do it using <em>VS Code</em>):</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">#SBATCH -o simple_job.log</span></span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="fu">sleep</span> 60 <span class="co"># hold for 60 seconds</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="bu">echo</span> <span class="st">&quot;This job is running on:&quot;</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="fu">hostname</span></span></code></pre></div>
<p>If we now re-run the script using <code>sbatch test_job.sh</code>, the output goes to a file named <code>simple_job.log</code>.</p>
<p>There are several other options we can specify when using SLURM, and we will encounter several more of them as we progress through the materials. Here are some of the most common ones (anything in <code>&lt;&gt;</code> is user input):</p>
<table>
<colgroup>
<col width="15%" />
<col width="84%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Command</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>-D &lt;path&gt;</code></td>
<td align="left"><em>working directory</em> used for the job. This is the directory that SLURM will use as a reference when running the job.</td>
</tr>
<tr class="even">
<td align="right"><code>-o &lt;path/filename&gt;</code></td>
<td align="left">file where the output that would normally be printed on the console is saved in. This is defined <em>relative</em> to the working directory set above.</td>
</tr>
<tr class="odd">
<td align="right"><code>-A &lt;name&gt;</code></td>
<td align="left">billing account. This is sometimes needed if you’re using HPC servers that charge you for their use. This information should be provided by your HPC admins.</td>
</tr>
<tr class="even">
<td align="right"><code>-p &lt;name&gt;</code></td>
<td align="left"><em>partition</em> name. Often HPC servers have different types of compute node setups (e.g. queues for fast jobs, or long jobs, or high-memory jobs, etc.). This option is used to choose which of these so-called “partitions” you want to run your job on. This information should be provided by your HPC admins.</td>
</tr>
<tr class="odd">
<td align="right"><code>-c &lt;number&gt;</code></td>
<td align="left">the number of CPUs you want to use for your job.</td>
</tr>
<tr class="even">
<td align="right"><code>-t &lt;HH:MM:SS&gt;</code></td>
<td align="left">the time you need for your job to run. This is not always easy to estimate in advance, so if you’re unsure you may want to request a good chunk of time. However, the more time you request for your job, the lower its priority in the queue.</td>
</tr>
<tr class="odd">
<td align="right"><code>--mem=&lt;number&gt;GB</code></td>
<td align="left">how much RAM memory you want for your job in gigabytes.</td>
</tr>
<tr class="even">
<td align="right"><code>-J &lt;name&gt;</code></td>
<td align="left">a name for the job.</td>
</tr>
</tbody>
</table>
<div class="note">
<p><strong>Default Resources</strong></p>
<p>If you don’t specify any options when submitting your jobs, you will get the default configured by the HPC admins. For example, in our training HPC, the defaults you will get are:</p>
<ul>
<li>10 seconds of running time (equivalent to <code>-t 00:00:10</code>)</li>
<li><em>training</em> partition (equivalent to <code>-p training</code>)</li>
<li>1 CPU (equivalent to <code>-c 1</code>)</li>
<li>1GB RAM (equivalent to <code>--mem=1GB</code>)</li>
</ul>
</div>
</div>
<div id="getting-job-information" class="section level2">
<h2>Getting Job Information</h2>
<p>After submitting a job, we may want to know:</p>
<ul>
<li>What is going on with my job? Is it running, has it finished?</li>
<li>If it finished, did it finish successfully, or did it fail?</li>
<li>How many resources (e.g. RAM) did it use?</li>
<li>What if I want to cancel a job because I realised there was a mistake in my script?</li>
</ul>
<p>You can check the status of any jobs in the queue by using:</p>
<pre class="console"><code>squeue -u &lt;user&gt;</code></pre>
<p>This gives you information about the job’s status: <code>PD</code> means it’s <em>pending</em> (waiting in the queue) and <code>R</code> means it’s <em>running</em>.</p>
<p>To check several statistics about a job (and whether it completed or failed), you can use:</p>
<pre class="console"><code>seff JOBID</code></pre>
<p>This shows you the status of the job, whether it completed or not, how many cores it used, how long it took to run and how much memory it used. Therefore, this command is very useful to determine suitable resources (e.g. RAM, time) next time you run a similar job.</p>
<p>Alternatively, you can use the <code>sacct</code> command, which allows displaying this and other information in a more condensed way (and for multiple jobs if you want to).</p>
<p>For example:</p>
<pre class="console"><code>sacct --format jobname,account,state,AllocCPUs,reqmem,maxrss,averss,elapsed -j JOBID</code></pre>
<ul>
<li><code>jobname</code> is the job’s name</li>
<li><code>account</code> is the account used for the job</li>
<li><code>state</code> gives you the state of the job</li>
<li><code>AllocCPUs</code> is the number of CPUs you requested for the job</li>
<li><code>reqmem</code> is the memory that you asked for (Mc or Gc indicates MB or GB per core; Mn or Gn indicates MB or GB per node)</li>
<li><code>maxrss</code> is the maximum memory used during the job <em>per core</em></li>
<li><code>averss</code> is the average memory used <em>per core</em></li>
<li><code>elapsed</code> how much time it took to run your job</li>
</ul>
<p>All the options available with <code>sacct</code> can be listed using <code>sacct -e</code>. If you forgot what the job id is, running <code>sacct</code> with no other options will show you information about your last few jobs.</p>
<div class="note">
<p>The <code>sacct</code> command may not be available on every HPC, as it depends on how it was configured by the admins.</p>
</div>
<p>You can also see other details about the job, such as the working directory and output directories it ran with:</p>
<pre class="console"><code>scontrol show job &lt;JOBID&gt;</code></pre>
<p>Finally, if you want to cancel a job, you can use:</p>
<pre class="console"><code>scancel &lt;JOBID&gt;</code></pre>
<p>And to cancel all your jobs simultaneously: <code>scancel -u &lt;USERNAME&gt;</code> (note that you will not be able to cancel other people’s jobs, so don’t worry about it).</p>
<div class="warning">
<p><strong>WATCH OUT</strong></p>
<p>When specifying the <code>-o</code> option including a directory name, if the output directory does not exist, <code>sbatch</code> will fail <em>without any errors</em>.</p>
<p>For example, let’s say that we would like to keep our job output files in a folder called “logs”. For the example above, we might set these #SBATCH options:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">#SBATCH -D /scratch/username/hpc_workshop/01-slurm_basics</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="co">#SBATCH -o logs/simple_job.log</span></span></code></pre></div>
<p>But, unless we create the <code>logs/</code> directory <em>before running the job</em>, <code>sbatch</code> will fail without telling us why.</p>
</div>
<div class="exercise">
In the “scripts” directory, you will find an R script called <code>pi_estimator.R</code>. This script tries to get an approximate estimate for the number Pi using a stochastic algorithm.
<details>
<p><summary>How does the algorithm work?</summary></p>
<p>If you are interested in the details, here is a short description of what the script does:</p>
<blockquote>
<p>The program generates a large number of random points on a 1×1 square centered on (½,½), and checks how many of these points fall inside the unit circle. On average, π/4 of the randomly-selected points should fall in the circle, so π can be estimated from 4f, where f is the observed fraction of points that fall in the circle. Because each sample is independent, this algorithm is easily implemented in parallel.</p>
</blockquote>
<div class="figure">
<img src="https://carpentries-incubator.github.io/hpc-intro/fig/pi.png" style="width:50.0%" alt="" />
<p class="caption">Estimating Pi by randomly placing points on a quarter circle. (Source: <a href="https://carpentries-incubator.github.io/hpc-intro/16-parallel/index.html">HPC Carpentry</a>)</p>
</div>
</details>
<p>If you were running this script interactively (i.e. directly from the console), you would use the R script interpreter: <code>Rscript scripts/pi_estimator.R</code>. Instead, we use a shell script to submit this to the job scheduler.</p>
<ol style="list-style-type: decimal">
<li>Edit the shell script in <code>slurm/estimate_pi.sh</code> by correcting the code where the word “FIXME” appears. Submit the job to SLURM and check its status in the queue.</li>
<li>How long did the job take to run?
<details>
<summary>Hint</summary>Use <!--`seff JOBID` or--> <code>scontrol show JOBID</code>.
</details></li>
<li>The number of samples used to estimate Pi can be modified using the <code>--nsamples</code> option of our script, defined in millions. The more samples we use, the more precise our estimate should be.
<ul>
<li>Adjust your SLURM submission script to use 500 million samples (<code>Rscript scripts/pi_estimator.R --nsamples 500</code>), and save the job output in <code>logs/estimate_pi_500M.log</code>.</li>
<li>Monitor the job status with <code>squeue</code> and <code>scontrol show JOBID</code>. <!-- If you find any issues, how would you fix them? --></li>
</ul></li>
</ol>
<details>
<p><summary>Answer</summary></p>
<p><strong>A1.</strong></p>
<p>In the shell script we needed to correct the user-specific details in the <code>#SBATCH</code> options. Also, we needed to specify the path to the script we wanted to run. This can be defined relative to the working directory that we’ve set with <code>-D</code>. For example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="co">#SBATCH -p training </span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="co">#SBATCH -D /scratch/USERNAME/hpc_workshop/  # working directory</span></span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="co">#SBATCH -o logs/estimate_pi.log  # standard output file</span></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="co">#SBATCH -c 1        # number of CPUs. Default: 1</span></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co">#SBATCH -t 00:10:00 # time for the job HH:MM:SS.</span></span>
<span id="cb12-7"><a href="#cb12-7"></a></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="co"># run the script</span></span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="ex">Rscript</span> scripts/pi_estimator.R</span></code></pre></div>
<p><strong>A2.</strong></p>
<p>As suggested in the hint, we can use the <code>seff</code> or <code>scontrol</code> commands for this:</p>
<pre class="console"><code>seff JOBID
scontrol show JOBID</code></pre>
<p>Replacing JOBID with the ID of the job we just ran.</p>
<p>If you cannot remember what the job id was, you can run <code>sacct</code> with no other options and it will list the last few jobs that you ran.</p>
<p>Strangely enough, the “Memory Utilized” is reported as 0.00MB. That’s very odd, since for sure our script must have used <em>some</em> memory to do the computation. The reason is that SLURM doesn’t always have time to pick memory usage spikes, and so it reports a zero. This is usually not an issue with longer-running jobs.</p>
<p><strong>A3.</strong></p>
<p>The modified script should look similar to this:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="co">#SBATCH -p training </span></span>
<span id="cb14-3"><a href="#cb14-3"></a><span class="co">#SBATCH -D /scratch/USERNAME/hpc_workshop/  # working directory</span></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co">#SBATCH -o logs/estimate_pi.log  # standard output file</span></span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="co">#SBATCH -c 1        # number of CPUs. Default: 1</span></span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="co">#SBATCH -t 00:10:00 # time for the job HH:MM:SS.</span></span>
<span id="cb14-7"><a href="#cb14-7"></a></span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="co"># run the script</span></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="ex">Rscript</span> scripts/pi_estimator.R --nsamples 500</span></code></pre></div>
<p>However, when we run this job, examining the output file (<code>cat logs/estimate_pi_500M.log</code>) will reveal:</p>
<pre><code>slurmstepd: error: Detected 1 oom-kill event(s) in step JOBID.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.</code></pre>
<p>Furthermore, if we use <code>seff</code> to get information about the job, it will show <code>State: OUT_OF_MEMORY (exit code 0)</code>.</p>
<p>This suggests that the job required more memory than we requested. To correct this problem, we would need to increase the memory requested to SLURM, adding to our script, for example, <code>#SBATCH --mem=10G</code> to request 10Gb of RAM memory for the job.</p>
<p>Again, <code>seff</code> is rather unhelpful in accurately reporting how much memory the job used. Clearly, it ran out of memory, but because it ran so fast SLURM didn’t register the memory usage peak.</p>
</details>
</div>
</div>
<div id="slurm-environment-variables" class="section level2">
<h2>SLURM Environment Variables</h2>
<p>One useful feature of SLURM jobs is the automatic creation of environment variables. Generally speaking, variables are a character that store a value within them, and can either be created by us, or sometimes they are automatically created by programs or available by default in our shell.</p>
<div class="note">
<details>
<p><summary>More about shell variables</summary></p>
<p>An example of a common shell environment variable is <code>$HOME</code>, which stores the path to the user’s <code>/home</code> directory. We can print the value of a variable with <code>echo $HOME</code>.</p>
<p>The syntax to create a variable ourselves is:</p>
<pre class="shell"><code>VARIABLE=&quot;value&quot;</code></pre>
<p>Notice that there should be <strong>no space between the variable name and its value</strong>.</p>
<p>If you want to create a variable with the result of evaluating a command, then the syntax is:</p>
<pre class="shell"><code>VARIABLE=$(command)</code></pre>
<p>Try these examples:</p>
<pre class="shell"><code># Make a variable with a path starting from the user&#39;s /home
DATADIR=&quot;$HOME/scratch/data/&quot;

# list files in that directory
ls $DATADIR

# create a variable with the output of that command
DATAFILES=$(ls $DATADIR)</code></pre>
</details>
</div>
<p>When you submit a job with SLURM, it creates several variables, all starting with the prefix <code>$SLURM_</code>. One useful variable is <code>$SLURM_CPUS_PER_TASK</code>, which stores how many CPUs we requested for our job. This means that we can use the variable to automatically set the number of CPUs for software that support multi-processing. We will see an example in the following exercise.</p>
<div class="exercise">
<p>The R script used in the previous exercise supports parallelisation of some of its internal computations. The number of CPUs used by the script can be modified using the <code>--ncpus</code> option. For example <code>pi_estimator.R --ncpus 2</code> would use two CPUs.</p>
<ol style="list-style-type: decimal">
<li>Modify your submission script to use the <code>$SLURM_CPUS_PER_TASK</code> variable to set the number of CPUs used by <code>pi_estimator.R</code>.</li>
<li>Submit the job a few times, each one using 1, 2 and then 8 CPUs. Make a note of each job’s ID.</li>
<li>Check how much time each job took to run (using <code>scontrol show job JOBID</code>). Did increasing the number of CPUs shorten the time it took to run?</li>
</ol>
<details>
<p><summary>Answer</summary></p>
<p><strong>A1.</strong></p>
<p>We can modify our submission script in the following manner:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="co">#SBATCH -p training     # partiton name</span></span>
<span id="cb19-3"><a href="#cb19-3"></a><span class="co">#SBATCH -D /scratch/</span><span class="al">FIXME</span><span class="co">/hpc_workshop/  # working directory</span></span>
<span id="cb19-4"><a href="#cb19-4"></a><span class="co">#SBATCH -o logs/estimate_pi.log      # output file</span></span>
<span id="cb19-5"><a href="#cb19-5"></a><span class="co">#SBATCH --mem=10G</span></span>
<span id="cb19-6"><a href="#cb19-6"></a><span class="co">#SBATCH -c 2                          # number of CPUs</span></span>
<span id="cb19-7"><a href="#cb19-7"></a></span>
<span id="cb19-8"><a href="#cb19-8"></a><span class="co"># launch the Pi estimator script using the number of CPUs that we are requesting from SLURM</span></span>
<span id="cb19-9"><a href="#cb19-9"></a><span class="ex">Rscript</span> exercises/pi_estimator.R --nsamples 500 --ncpus <span class="va">$SLURM_CPUS_PER_TASK</span></span></code></pre></div>
<p>We can run the job multiple times by modifying the <code>#SBATCH -c</code> option.</p>
<p>After running each job we can use <code>scontrol show job JOBID</code> command to obtain information about how long it took to run.</p>
<p><code>seff JOBID</code></p>
<!--
After running each job we can use the `seff` command to obtain information about how long it took to run:

`seff JOBID`

Alternatively, since we want to compare several jobs, we could also use `sacct`:

`sacct -o JobID,elapsed -j JOBID1,JOBID2,JOBID3`
-->
<p>In this case, it does seem that increasing the number of CPUs shortens the time the job takes to run. However, the increase is not linear at all. Going from 1 to 2 CPUs speeds things up a bit, but beyond that we don’t get much better performance. This is possibly because there are other computational costs to do with this kind of parallelisation (e.g. keeping track of what each parallel thread is doing).</p>
</details>
</div>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<div class="highlight">
<h4 id="key-points">Key Points</h4>
<ul>
<li>Include the commands you want to run on the HPC in a shell script.
<ul>
<li>Always remember to include <code>#!/bin/bash</code> as the first line of your script.</li>
</ul></li>
<li>Submit jobs to the scheduler using <code>sbatch submission_script.sh</code>.</li>
<li>Customise the jobs by including <code>#SBATCH</code> options at the top of your script (see table in the materials above for a summary of options).
<ul>
<li>As a good practice, always define an output file with <code>#SBATCH -o</code>. All the information about the job will be saved in that file, including any errors.</li>
</ul></li>
<li>Check the status of a submitted job by using <code>squeue -u USERNAME</code> and <code>sacct -j JOBID</code>.</li>
<li>To cancel a running job use <code>scancel JOBID</code>.</li>
</ul>
<h4 id="further-resources">Further resources</h4>
<ul>
<li><a href="https://slurm.schedmd.com/pdfs/summary.pdf">SLURM cheatsheet</a></li>
</ul>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
